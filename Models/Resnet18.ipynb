{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Necessary libraries"
      ],
      "metadata": {
        "id": "fHXbLPZHTBWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-07T15:19:44.287656Z",
          "iopub.execute_input": "2023-05-07T15:19:44.288607Z",
          "iopub.status.idle": "2023-05-07T15:19:44.294250Z",
          "shell.execute_reply.started": "2023-05-07T15:19:44.288571Z",
          "shell.execute_reply": "2023-05-07T15:19:44.293039Z"
        },
        "trusted": true,
        "id": "NB5j3HCNTBWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-07T15:19:44.303418Z",
          "iopub.execute_input": "2023-05-07T15:19:44.303837Z",
          "iopub.status.idle": "2023-05-07T15:19:55.798444Z",
          "shell.execute_reply.started": "2023-05-07T15:19:44.303808Z",
          "shell.execute_reply": "2023-05-07T15:19:55.797172Z"
        },
        "trusted": true,
        "id": "AVqoufSpTBWG",
        "outputId": "88f456b3-1565-4527-f947-1f52f58cc6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.22.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: torch==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.0.0+cpu)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (1.11.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio torchmetrics\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-07T15:19:55.800578Z",
          "iopub.execute_input": "2023-05-07T15:19:55.800962Z"
        },
        "trusted": true,
        "id": "5YVg3EXZTBWH",
        "outputId": "7a2d2d63-19c9-4a5c-82a4-28e5a34d25a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1+cpu)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.0.1+cpu)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (0.11.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.22.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.22.0"
      ],
      "metadata": {
        "trusted": true,
        "id": "8U7QerkpTBWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms"
      ],
      "metadata": {
        "trusted": true,
        "id": "xpeKxx0TTBWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "trusted": true,
        "id": "HzRrFKe9TBWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the labels dataframe."
      ],
      "metadata": {
        "id": "iILQHAcLTBWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "N5Zxbl50TBWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "i9qb4E6eTBWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While looking at labels, we can see that there is a **patientid** column at first which is a unique patient id.\n",
        "\n",
        "Columns`x,y, left, right` represents the `x` and `y` coordinates and the `left` and `right` position of the classified pneumonia region.\n",
        "\n",
        "The final column `Target` is used to denote whether patient is suffering from pneumonia or not."
      ],
      "metadata": {
        "id": "FFbe2jSiTBWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Duplicates\n",
        "\n",
        "labels = labels.drop_duplicates(\"patientId\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MCPP0yusTBWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a `ROOT_PATH` that takes a path to our train dataset.\n",
        "\n",
        "Additionally, let's define a `SAVE_PATH` that defines path to the place where our processed images are saved."
      ],
      "metadata": {
        "id": "2lHeoDogTBWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = Path(\"/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/\")\n",
        "SAVE_PATH = Path(\"Processed\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-t4dK5GMTBWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at some example images.\n",
        "\n",
        "Let's create 3x3 subplots to view 9 images along with their labels."
      ],
      "metadata": {
        "id": "p52NwnRkTBWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axis = plt.subplots(3, 3, figsize = (9, 9))\n",
        "c = 0\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        # Start reading the files.\n",
        "        patient_id = labels.patientId.iloc[c]\n",
        "        \n",
        "        # Create a path to the dicom file of this particular patient/\n",
        "        dcm_path = ROOT_PATH/patient_id\n",
        "        \n",
        "        # Add .dcm extension\n",
        "        dcm_path = dcm_path.with_suffix(\".dcm\")\n",
        "        \n",
        "        # Reading the dicom file\n",
        "        dcm = pydicom.read_file(dcm_path).pixel_array\n",
        "        \n",
        "        # Extract the labels of the particular patient from labels dataframe\n",
        "        label = labels['Target'].iloc[c]\n",
        "        \n",
        "        # Visualize the image\n",
        "        axis[i][j].imshow(dcm, cmap = \"bone\")\n",
        "        axis[i][j].set_title(label)\n",
        "        \n",
        "        c += 1\n",
        "        \n",
        "         \n",
        "        "
      ],
      "metadata": {
        "trusted": true,
        "id": "FSIK0XltTBWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Preprocessing Images"
      ],
      "metadata": {
        "id": "O6ph9UsQTBWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we standardize each image pixels by dividing it by 255.\n",
        "\n",
        "Also, our images are way too large for current neural network architectures to process. So, we need to resize them to shape of 224x224.\n",
        "\n",
        "To use less space when storing the images, we convert them to `float16`"
      ],
      "metadata": {
        "id": "g4ESEkaCTBWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization \n",
        "sums, sums_squared = 0, 0\n",
        "\n",
        "# Loop over all patient ids\n",
        "# To decide if a data is used as training data or validation data\n",
        "# We can use the enumerate \n",
        "\n",
        "for c, patient_id, in enumerate(tqdm(labels.patientId)):\n",
        "    # Start reading the files.\n",
        "    patient_id = labels.patientId.iloc[c]\n",
        "        \n",
        "    # Create a path to the dicom file of this particular patient/\n",
        "    dcm_path = ROOT_PATH/patient_id\n",
        "\n",
        "    # Add .dcm extension\n",
        "    dcm_path = dcm_path.with_suffix(\".dcm\")\n",
        "\n",
        "    # Reading the dicom file and dividing the pixel array by 255\n",
        "    dcm = pydicom.read_file(dcm_path).pixel_array\n",
        "    \n",
        "    # Resizing the image and converting it's type\n",
        "    dcm_array = cv2.resize(dcm, (224, 224)).astype(np.float16)\n",
        "    \n",
        "    # Storing the label in 'label'\n",
        "    label = labels.Target.iloc[c]\n",
        "    \n",
        "    # Identify training/validation\n",
        "    train_or_val = \"train\" if c < 24000 else \"val\"\n",
        "    \n",
        "    # Save preprocessed images\n",
        "    current_save_path = SAVE_PATH/train_or_val/str(label)\n",
        "    current_save_path.mkdir(parents = True, exist_ok = True)\n",
        "    np.save(current_save_path/patient_id, dcm_array)\n",
        "    \n",
        "    \n",
        "    # Update sums and sums_squared\n",
        "    normalizer = 224*224\n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "Ikq369FITBWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = 0.49\n",
        "std = 0.24"
      ],
      "metadata": {
        "trusted": true,
        "id": "E59_3CiSTBWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Validation Dataset"
      ],
      "metadata": {
        "id": "Oo2HmukoTBWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the generate the data in required format, we can make use of dataset class."
      ],
      "metadata": {
        "id": "QAc5k9FhTBWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(path):\n",
        "    return np.load(path).astype(np.float32)"
      ],
      "metadata": {
        "trusted": true,
        "id": "y9Tj0rtCTBWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can define our train and validation transform:"
      ],
      "metadata": {
        "id": "5ZNlQhlFTBWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "    transforms.RandomAffine(degrees = (-5, 5), translate = (0, 0.05), scale = (0.9, 1.1)),\n",
        "    transforms.RandomResizedCrop((224, 224), scale = (0.35, 1))\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "xMw6Hx-aTBWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader\n",
        "\n",
        "train_dataset = torchvision.datasets.DatasetFolder(\"/kaggle/working/Processed/train/\", loader = load_file, extensions = \"npy\", transform = train_transforms)\n",
        "\n",
        "val_dataset = torchvision.datasets.DatasetFolder(\"/kaggle/working/Processed/val/\", loader = load_file, extensions = \"npy\", transform = val_transforms)"
      ],
      "metadata": {
        "trusted": true,
        "id": "k2_BcxQvTBWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axis = plt.subplots(2, 2, figsize=(9, 9))\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        random_index = np.random.randint(0, 24000)\n",
        "        x_ray, label = train_dataset[random_index]\n",
        "        axis[i][j].imshow(x_ray[0], cmap = \"bone\")\n",
        "        axis[i][j].set_title(label)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "m0g-UnRWTBWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_workers = 4"
      ],
      "metadata": {
        "trusted": true,
        "id": "faxZRVknTBWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "trusted": true,
        "id": "oyTnuYEqTBWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "eA76uyNuTBWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_dataset.targets, return_counts = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mS0_QCErTBWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset is heavily imbalanced. So, we will be doing weighted loss."
      ],
      "metadata": {
        "id": "jrI4qh3rTBWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observing the Resnet18 architecture\n",
        "\n",
        "torchvision.models.resnet18()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ChW4PngzTBWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PneumoniaModel(pl.LightningModule):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self):\n",
        "        super(PneumoniaModel, self).__init__()\n",
        "        self.model = torchvision.models.resnet18()\n",
        "        self.model.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.model.fc = torch.nn.Linear(in_features = 512, out_features = 1, bias = True)\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = 1e-4)\n",
        "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor([3]))\n",
        "        \n",
        "        self.train_acc = torchmetrics.Accuracy(task = \"binary\")\n",
        "        self.val_acc = torchmetrics.Accuracy(task = \"binary\")\n",
        "        #self.test_acc = torchmetrics.Accuracy()\n",
        "        \n",
        "        \n",
        "        \n",
        "    # Activation\n",
        "    def forward(self, data):\n",
        "        pred = self.model(data)\n",
        "        return pred\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x_ray, label = batch\n",
        "        label = label.float()\n",
        "        pred = self(x_ray)[:, 0]\n",
        "        loss = self.loss_fn(pred, label)\n",
        "        \n",
        "        self.log(\"Train Loss\", loss)\n",
        "        self.log(\"Step Train ACC\", self.train_acc(torch.sigmoid(pred), label.int()))\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    \n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"Train ACC\", self.train_acc.compute())\n",
        "        \n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x_ray, label = batch\n",
        "        label = label.float()\n",
        "        pred = self(x_ray)[:, 0]\n",
        "        loss = self.loss_fn(pred, label)\n",
        "        \n",
        "        self.log(\"Val Loss\", loss)\n",
        "        self.log(\"Step Val ACC\", self.val_acc(torch.sigmoid(pred), label.int()))\n",
        "\n",
        "        \n",
        "        \n",
        "       \n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"Val ACC\", self.val_acc.compute())\n",
        "        \n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        return[self.optimizer]\n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "28X6dts-TBWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PneumoniaModel()"
      ],
      "metadata": {
        "trusted": true,
        "id": "SoKLK9RQTBWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor = \"Val ACC\",\n",
        "    save_top_k = 1,\n",
        "    mode = \"max\",\n",
        "    dirpath = \"./saved_models\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "NSGV4523TBWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the trainer\n",
        "trainer = pl.Trainer(logger = TensorBoardLogger(save_dir = \"./logs\"), log_every_n_steps = 64, callbacks = checkpoint_callback, max_epochs = 10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "t0hOEP2iTBWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-hGBKntMTBWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "xALfgca4TBWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PneumoniaModel.load_from_checkpoint(\"/kaggle/working/saved_models/epoch=0-step=375.ckpt\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fqnyH8N-TBWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "id": "UEehduGXTBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "azH5_Q_GTBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in tqdm(val_dataset):\n",
        "        data = data.to(device).float().unsqueeze(0)\n",
        "        \n",
        "        # Calculate probabilities\n",
        "        pred = torch.sigmoid(model(data)[0].cpu())\n",
        "        \n",
        "        preds.append(pred)\n",
        "        labels.append(label)\n",
        "preds = torch.tensor(preds)\n",
        "labels = torch.tensor(labels).int()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ixAF9DA8TBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "acc = torchmetrics.Accuracy(task = \"binary\")(preds, labels)\n",
        "\n",
        "# Precision\n",
        "precision = torchmetrics.Precision(task = \"binary\")(preds, labels)\n",
        "\n",
        "# Recall\n",
        "recall = torchmetrics.Recall(task = \"binary\")(preds, labels)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = torchmetrics.ConfusionMatrix(num_classes=2, task = \"binary\")(preds, labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-wHV2R1ATBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy : {acc}\")\n",
        "print(f\"Precision : {precision}\")\n",
        "print(f\"Recall : {recall}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "BifWi6qLTBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Activation Map\n",
        "Learning deep features for discriminative localization."
      ],
      "metadata": {
        "id": "RC6hne8KTBWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(path):\n",
        "    return np.load(path).astype(np.float32)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_XLdM27jTBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.49, 0.248),\n",
        "    transforms.Resize((224, 224))\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "JZweQtiITBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import DatasetFolder"
      ],
      "metadata": {
        "trusted": true,
        "id": "aCZZ4T-BTBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = torchvision.datasets.DatasetFolder(\"/kaggle/working/Processed/val/\", loader = load_file, extensions = 'npy', transform = val_transforms)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RV_7a2lnTBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_model = torchvision.models.resnet18()"
      ],
      "metadata": {
        "trusted": true,
        "id": "xXPzYnW2TBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(temp_model.children())"
      ],
      "metadata": {
        "trusted": true,
        "id": "8M5wBvvMTBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(temp_model.children())[:-2]"
      ],
      "metadata": {
        "trusted": true,
        "id": "WwE8grsjTBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.Sequential(*list(temp_model.children())[:-2])"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ak7260pCTBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PneumoniaModel(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(PneumoniaModel, self).__init__()\n",
        "        self.model = torchvision.models.resnet18()\n",
        "        self.model.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels=64, kernel_size=(7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
        "        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n",
        "        \n",
        "        self.feature_map = torch.nn.Sequential(*list(temp_model.children())[:-2])\n",
        "        \n",
        "        \n",
        "    def forward(self, data):\n",
        "        feature_map = self.feature_map(data)\n",
        "        avg_pool_output = torch.nn.functional.adaptive_avg_pool2d(input=feature_map, output_size = (1, 1))\n",
        "        avg_output_flattened = torch.flatten(avg_pool_output)\n",
        "        pred = self.model.fc(avg_output_flattened)\n",
        "        return pred, feature_map"
      ],
      "metadata": {
        "trusted": true,
        "id": "iIMD788ETBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PneumoniaModel.load_from_checkpoint(\"/kaggle/working/saved_models/epoch=0-step=375.ckpt\", strict = False)\n",
        "model.eval();"
      ],
      "metadata": {
        "trusted": true,
        "id": "QmgWoQdbTBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cam(model, img):\n",
        "    with torch.no_grad():\n",
        "        pred, features = model(img.unsqueeze(0))\n",
        "    features = features.reshape((512, 49))\n",
        "    weight_params = list(model.model.fc.parameters())[0]\n",
        "    weight = weight_params[0].detach()\n",
        "    \n",
        "    cam = torch.matmul(weight, features)\n",
        "    cam_img = cam.reshape(7, 7).cpu()\n",
        "    return cam_img, torch.sigmoid(pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RVfkDbxFTBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(img, cam, pred):\n",
        "    img = img[0]\n",
        "    cam = transforms.functional.resize(cam.unsqueeze(0), (224, 224))[0]\n",
        "    \n",
        "    fig, axis = plt.subplots(1, 2)\n",
        "    axis[0].imshow(img, cmap = 'bone')\n",
        "    axis[1].imshow(img, cmap= 'bone')\n",
        "    axis[1].imshow(cam, alpha=0.5, cmap=\"jet\")\n",
        "    plt.title(pred>0.5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ypFYxuOTTBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset[-6][0].shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "TFnfjk7STBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.cat([val_dataset[-6][0], val_dataset[-6][0], val_dataset[-6][0]], dim=0)\n",
        "activation_map, pred = cam(model, img)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aZmxALK5TBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(img, activation_map, pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nDrPVLe2TBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.cat([val_dataset[-50][0], val_dataset[-50][0], val_dataset[-50][0]], dim=0)\n",
        "activation_map, pred = cam(model, img)\n",
        "visualize(img, activation_map, pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "U60u3RMqTBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.cat([val_dataset[50][0], val_dataset[50][0], val_dataset[50][0]], dim=0)\n",
        "activation_map, pred = cam(model, img)\n",
        "visualize(img, activation_map, pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CVXSRAzjTBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.cat([val_dataset[200][0], val_dataset[200][0], val_dataset[200][0]], dim=0)\n",
        "activation_map, pred = cam(model, img)\n",
        "visualize(img, activation_map, pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "N85oPyztTBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "weLKbO-kTBWW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}